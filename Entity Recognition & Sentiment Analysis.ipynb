{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Entity Recognition & Sentiment Analysis</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Recognition of Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to the MongoDB database 'EngTweetsDb' where the tweets are stored\n",
    "import pymongo\n",
    "MONGO_HOST = 'mongodb://localhost/EngTweetsDb'\n",
    "conn = pymongo.MongoClient(MONGO_HOST)[\"EngTweetsDb\"][\"en_tweets_col\"]\n",
    "conn.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using 'NLTK' package to perform entity recognition\n",
    "import os\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting the necessary path\n",
    "java_path = \"C:/Program Files/Java/jdk1.8.0_161/bin/java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Invoking an instance of 'StanfordNERTagger'\n",
    "st = StanfordNERTagger('C:/Users/Dell user/Desktop/Stanford/stanford-ner-2018-02-27/classifiers/english.conll.4class.distsim.crf.ser.gz',\n",
    "                       'C:/Users/Dell user/Desktop/Stanford/stanford-ner-2018-02-27/stanford-ner.jar',\n",
    "                       encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a new MongoDB databse 'Entity' to store entities\n",
    "MONGO_HOST1 = 'mongodb://localhost/Entity'\n",
    "conn1 = pymongo.MongoClient(MONGO_HOST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a function to extract the entities\n",
    "def entity_recognizer(text):\n",
    "    entity = st.tag(txt.split())\n",
    "    record = {'entity': entity}\n",
    "    db1.entity_record.save(record)\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extracting only the tweet text from the database\n",
    "all_text_id =(list(conn.find({},{\"text\":1})))\n",
    "text_only = []\n",
    "for i in range(conn.count()):\n",
    "    text_str = all_text_id[i][\"text\"]\n",
    "    text_only.append(text_str)\n",
    "print(text_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calling 'entity_recognizer' function on the tweet text\n",
    "db1 = conn1.Entity\n",
    "entity_list = []\n",
    "entity_list_nw = []\n",
    "for txt in text_only:\n",
    "    entity = entity_recognizer(txt)\n",
    "    entity_list.append(entity)\n",
    "    entity_list_nw = entity_list_nw + entity\n",
    "print(entity_list_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting the tweet text into lowercase\n",
    "l = [(item[0].lower(),item[1]) for item in entity_list_nw]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using 'collections' package to count the number of entities categorised as 'PERSON', 'ORGANISATION' and 'LOCATION'\n",
    "from collections import Counter\n",
    "print(Counter(x[0] for x in l if x[1]!='O' ))\n",
    "print(Counter(x[1] for x in l if x[1]!='O' ))\n",
    "counts = Counter(x[0] for x in l if x[1]!='O')\n",
    "print(counts.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extracting the top-five entities\n",
    "top_entities=list(Counter(x[0] for x in counts.most_common() if x[1]!='O'))\n",
    "top_five = top_entities[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Printing 'top_five' list of entities\n",
    "top_five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A) Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using 'textblob' package to do find out polarity of the tweet text which is then used to categorize tweets as positive, neutral or negative.\n",
    "from textblob import TextBlob\n",
    "def get_tweet_sentiment(twt):\n",
    "        \n",
    "        analysis = TextBlob(twt)\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a list of tuples containing the text and the sentiment: positive/neutral/negative\n",
    "analysis = []\n",
    "for twt in text_only:\n",
    "    senti = (twt, get_tweet_sentiment(twt))\n",
    "    analysis.append(senti)\n",
    "    \n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Printing the percentage of positive, neutral and negative sentiments in all the tweets\n",
    "counts = Counter(x[1] for x in analysis)\n",
    "print('No. of positive sentiments    = {}'.format(counts['positive']))\n",
    "print('No. of neutral sentiments     = {}'.format(counts['neutral']))\n",
    "print('No. of negative sentiments    = {}'.format(counts['negative']))\n",
    "print('Total tweets analysed         = {}'.format(len(analysis)))\n",
    "print('Percentage of positive tweets = {0:10.3f} %'.format((100*counts['positive']/len(analysis))))\n",
    "print('Percentage of neutral tweets  = {0:10.3f} %'.format((100*counts['neutral']/len(analysis))))\n",
    "print('Percentage of negative tweets = {0:10.3f} %'.format((100*counts['negative']/len(analysis))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## (B) News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Connecting to the MongoDB database 'News' where the news articles corresponding to five most-occurring entities are stored\n",
    "import pymongo\n",
    "MONGO_HOST = 'mongodb://localhost/News'\n",
    "conn2 = pymongo.MongoClient(MONGO_HOST)[\"News\"]\n",
    "db2 = conn1.articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Passing the list of five most frequently occurring entities in tweets\n",
    "top_five = ['hindu', 'justin', 'bieber', '#bbmas', 'trump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extracting the 'content' information from the stored news articles\n",
    "content_id =(list(db2.find({})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a function to extract only the description/body of the news articles\n",
    "def textprocessor(s):\n",
    "    start=\"'body':\"\n",
    "    end=\"'categories':\"\n",
    "    body=(s.split(start))[1].split(end)[0]\n",
    "    return body.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Storing content of news article corresponding to each entity of 'top_five' list in five different lists, namely, body1_list, body2_list, body3_list, body4_list and body5_list\n",
    "body1_list = []\n",
    "for i in range(0,10):\n",
    "    s = content_id[i][top_five[0]]\n",
    "    body1 = textprocessor(s)\n",
    "    print(top_five[0])\n",
    "    print(body1)\n",
    "    print(\"\\n\")\n",
    "    body1_list.append(body1)\n",
    "    \n",
    "body2_list = []    \n",
    "for i in range(11,20):\n",
    "    s = content_id[i][top_five[1]]\n",
    "    body2 = textprocessor(s)\n",
    "    print(top_five[1])\n",
    "    print(body2)\n",
    "    print(\"\\n\")\n",
    "    body2_list.append(body2)\n",
    "body3_list=[]    \n",
    "for i in range(21,30):\n",
    "    s = content_id[i][top_five[2]]\n",
    "    body3 = textprocessor(s)\n",
    "    print(top_five[2])\n",
    "    print(body3)\n",
    "    print(\"\\n\")\n",
    "    body3_list.append(body3)\n",
    "body4_list = []    \n",
    "for i in range(31,40):\n",
    "    s = content_id[i][top_five[3]]\n",
    "    body4 = textprocessor(s)\n",
    "    print(top_five[3])\n",
    "    print(body4)\n",
    "    print(\"\\n\")\n",
    "    body4_list.append(body4)\n",
    "body5_list = []    \n",
    "for i in range(41,50):\n",
    "    s = content_id[i][top_five[4]]\n",
    "    body5 = textprocessor(s)\n",
    "    print(top_five[4])\n",
    "    print(body5)\n",
    "    print(\"\\n\")\n",
    "    body5_list.append(body5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a function to extract the entities\n",
    "db3 = conn2.content_entity_record\n",
    "def entity_recognizer_news(text):\n",
    "    entity = st.tag(txt.split(' '))\n",
    "    print(entity)\n",
    "    record = {'entity': entity}\n",
    "    db3.content_entity_record.save(record)\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using 'textblob' package to do find out polarity of the tweet text which is then used to categorize tweets as positive, neutral or negative.\n",
    "from textblob import TextBlob\n",
    "def get_news_sentiment(txt):\n",
    "        \n",
    "        analysis = TextBlob(txt)\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Storing tuple of content and its sentiment in lists, namely, body1_analysis, body2_analysis, body3_analysis, body4_analysis and body5_analysis \n",
    "body1_analysis = []\n",
    "for txt in body1_list:\n",
    "    senti = (get_news_sentiment(txt), txt)\n",
    "    body1_analysis.append(senti)\n",
    "print(body1_analysis)\n",
    "\n",
    "body2_analysis = []\n",
    "for txt in body2_list:\n",
    "    senti = (get_news_sentiment(txt), txt)\n",
    "    body2_analysis.append(senti)\n",
    "print(body2_analysis)\n",
    "\n",
    "body3_analysis = []\n",
    "for txt in body3_list:\n",
    "    senti = (get_news_sentiment(txt), txt)\n",
    "    body3_analysis.append(senti)\n",
    "print(body3_analysis)\n",
    "\n",
    "body4_analysis = []\n",
    "for txt in body4_list:\n",
    "    senti = (get_news_sentiment(txt), txt)\n",
    "    body4_analysis.append(senti)\n",
    "print(body4_analysis)\n",
    "\n",
    "body5_analysis = []\n",
    "for txt in body5_list:\n",
    "    senti = (get_news_sentiment(txt), txt)\n",
    "    body5_analysis.append(senti)\n",
    "print(body5_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Printing the percentage of positive, neutral and negative sentiments for each entity list, namely, body1_analysis, body2_analysis, body3_analysis, body4_analysis and body5_analysis\n",
    "from collections import Counter\n",
    "\n",
    "counts6 = Counter(x[0] for x in body1_analysis)\n",
    "print(top_five[0])\n",
    "print('No. of positive sentiments    = {}'.format(counts6['positive']))\n",
    "print('No. of neutral sentiments     = {}'.format(counts6['neutral']))\n",
    "print('No. of negative sentiments    = {}'.format(counts6['negative']))\n",
    "print('Total tweets analysed         = {}'.format(len(body1_analysis)))\n",
    "print('Percentage of positive tweets = {0:10.3f} %'.format((100*counts6['positive']/len(body1_analysis))))\n",
    "print('Percentage of neutral tweets  = {0:10.3f} %'.format((100*counts6['neutral']/len(body1_analysis))))\n",
    "print('Percentage of negative tweets = {0:10.3f} %'.format((100*counts6['negative']/len(body1_analysis))))\n",
    "print('\\n')\n",
    "\n",
    "counts7 = Counter(x[0] for x in body2_analysis)\n",
    "print(top_five[1])\n",
    "print('No. of positive sentiments    = {}'.format(counts7['positive']))\n",
    "print('No. of neutral sentiments     = {}'.format(counts7['neutral']))\n",
    "print('No. of negative sentiments    = {}'.format(counts7['negative']))\n",
    "print('Total tweets analysed         = {}'.format(len(body2_analysis)))\n",
    "print('Percentage of positive tweets = {0:10.3f} %'.format((100*counts7['positive']/len(body2_analysis))))\n",
    "print('Percentage of neutral tweets  = {0:10.3f} %'.format((100*counts7['neutral']/len(body2_analysis))))\n",
    "print('Percentage of negative tweets = {0:10.3f} %'.format((100*counts7['negative']/len(body2_analysis))))\n",
    "print('\\n')\n",
    "\n",
    "counts8 = Counter(x[0] for x in body3_analysis)\n",
    "print(top_five[2])\n",
    "print('No. of positive sentiments    = {}'.format(counts8['positive']))\n",
    "print('No. of neutral sentiments     = {}'.format(counts8['neutral']))\n",
    "print('No. of negative sentiments    = {}'.format(counts8['negative']))\n",
    "print('Total tweets analysed         = {}'.format(len(body3_analysis)))\n",
    "print('Percentage of positive tweets = {0:10.3f} %'.format((100*counts8['positive']/len(body3_analysis))))\n",
    "print('Percentage of neutral tweets  = {0:10.3f} %'.format((100*counts8['neutral']/len(body3_analysis))))\n",
    "print('Percentage of negative tweets = {0:10.3f} %'.format((100*counts8['negative']/len(body3_analysis))))\n",
    "print('\\n')\n",
    "\n",
    "counts9 = Counter(x[0] for x in body4_analysis)\n",
    "print(top_five[3])\n",
    "print('No. of positive sentiments    = {}'.format(counts9['positive']))\n",
    "print('No. of neutral sentiments     = {}'.format(counts9['neutral']))\n",
    "print('No. of negative sentiments    = {}'.format(counts9['negative']))\n",
    "print('Total tweets analysed         = {}'.format(len(body4_analysis)))\n",
    "print('Percentage of positive tweets = {0:10.3f} %'.format((100*counts9['positive']/len(body4_analysis))))\n",
    "print('Percentage of neutral tweets  = {0:10.3f} %'.format((100*counts9['neutral']/len(body4_analysis))))\n",
    "print('Percentage of negative tweets = {0:10.3f} %'.format((100*counts9['negative']/len(body4_analysis))))\n",
    "print('\\n')\n",
    "\n",
    "counts10 = Counter(x[0] for x in body5_analysis)\n",
    "print(top_five[4])\n",
    "print('No. of positive sentiments    = {}'.format(counts10['positive']))\n",
    "print('No. of neutral sentiments     = {}'.format(counts10['neutral']))\n",
    "print('No. of negative sentiments    = {}'.format(counts10['negative']))\n",
    "print('Total tweets analysed         = {}'.format(len(body5_analysis)))\n",
    "print('Percentage of positive tweets = {0:10.3f} %'.format((100*counts10['positive']/len(body5_analysis))))\n",
    "print('Percentage of neutral tweets  = {0:10.3f} %'.format((100*counts10['neutral']/len(body5_analysis))))\n",
    "print('Percentage of negative tweets = {0:10.3f} %'.format((100*counts10['negative']/len(body5_analysis))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (C) Finding and analysing sentiment of tweets corresponding to each entity in 'top_five' list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Connecting to the MongoDB database 'EngTweetsDb' where the tweets are stored\n",
    "client = pymongo.MongoClient(MONGO_HOST)\n",
    "db1 = client.EngTweetsDb\n",
    "db1.en_tweets_col.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding tweets corresponding to each entity in 'top_five' list and storing it in list\n",
    "one_tweets = db1.en_tweets_col.find({\"text\" : { '$regex' : 'hindu', '$options':'i'}})\n",
    "one_only = []\n",
    "for i in range(one_tweets.count()):\n",
    "    one_str = one_tweets[i]['text']\n",
    "    one_only.append(one_str)\n",
    "print(one_only)\n",
    "\n",
    "two_tweets = db1.en_tweets_col.find({\"text\" : { '$regex' : 'justin', '$options':'i'}})\n",
    "two_only = []\n",
    "for i in range(two_tweets.count()):\n",
    "    two_str = two_tweets[i]['text']\n",
    "    two_only.append(two_str)\n",
    "print(two_only)\n",
    "\n",
    "three_tweets = db1.en_tweets_col.find({\"text\" : { '$regex' : 'bieber', '$options':'i'}})\n",
    "three_only = []\n",
    "for i in range(three_tweets.count()):\n",
    "    three_str = three_tweets[i]['text']\n",
    "    three_only.append(three_str)\n",
    "print(three_only)\n",
    "\n",
    "four_tweets = db1.en_tweets_col.find({\"text\" : { '$regex' : '#bbmas', '$options':'i'}})\n",
    "four_only = []\n",
    "for i in range(four_tweets.count()):\n",
    "    four_str = four_tweets[i]['text']\n",
    "    four_only.append(four_str)\n",
    "print(four_only)\n",
    "\n",
    "five_tweets = db1.en_tweets_col.find({\"text\" : { '$regex' : top_five[4], '$options':'i'}})\n",
    "five_only = []\n",
    "for i in range(five_tweets.count()):\n",
    "    five_str = five_tweets[i]['text']\n",
    "    five_only.append(five_str)\n",
    "print(five_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Storing tuple of tweet text and its sentiment in lists, namely, one_analysis, two_analysis, three_analysis, four_analysis and five_analysis \n",
    "one_analysis = []\n",
    "for txt in one_only:\n",
    "    senti = (get_tweet_sentiment(txt), txt)\n",
    "    one_analysis.append(senti)\n",
    "print(one_analysis)\n",
    "\n",
    "two_analysis = []\n",
    "for txt in two_only:\n",
    "    senti = (get_tweet_sentiment(txt), txt)\n",
    "    two_analysis.append(senti)    \n",
    "print(two_analysis)\n",
    "\n",
    "three_analysis = []\n",
    "for txt in three_only:\n",
    "    senti = (get_tweet_sentiment(txt), txt)\n",
    "    three_analysis.append(senti)    \n",
    "print(three_analysis)\n",
    "\n",
    "four_analysis = []\n",
    "for txt in four_only:\n",
    "    senti = (get_tweet_sentiment(txt), txt)\n",
    "    four_analysis.append(senti)    \n",
    "print(four_analysis)\n",
    "\n",
    "five_analysis = []\n",
    "for txt in five_only:\n",
    "    senti = (get_tweet_sentiment(txt), txt)\n",
    "    five_analysis.append(senti)    \n",
    "print(five_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Printing the percentage of positive, neutral and negative sentiments for each entity list, namely, one_analysis, two_analysis, three_analysis, four_analysis and five_analysis\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "counts1 = Counter(x[0] for x in one_analysis)\n",
    "print(top_five[0])\n",
    "print('No. of positive sentiments    = {}'.format(counts1['positive']))\n",
    "print('No. of neutral sentiments     = {}'.format(counts1['neutral']))\n",
    "print('No. of negative sentiments    = {}'.format(counts1['negative']))\n",
    "print('Total tweets analysed         = {}'.format(len(one_analysis)))\n",
    "print('Percentage of positive tweets = {0:10.3f} %'.format((100*counts1['positive']/len(one_analysis))))\n",
    "print('Percentage of neutral tweets  = {0:10.3f} %'.format((100*counts1['neutral']/len(one_analysis))))\n",
    "print('Percentage of negative tweets = {0:10.3f} %'.format((100*counts1['negative']/len(one_analysis))))\n",
    "print('\\n')\n",
    "\n",
    "counts2 = Counter(x[0] for x in two_analysis)\n",
    "print(top_five[1])\n",
    "print('No. of positive sentiments    = {}'.format(counts2['positive']))\n",
    "print('No. of neutral sentiments     = {}'.format(counts2['neutral']))\n",
    "print('No. of negative sentiments    = {}'.format(counts2['negative']))\n",
    "print('Total tweets analysed         = {}'.format(len(two_analysis)))\n",
    "print('Percentage of positive tweets = {0:10.3f} %'.format((100*counts2['positive']/len(two_analysis))))\n",
    "print('Percentage of neutral tweets  = {0:10.3f} %'.format((100*counts2['neutral']/len(two_analysis))))\n",
    "print('Percentage of negative tweets = {0:10.3f} %'.format((100*counts2['negative']/len(two_analysis))))\n",
    "print('\\n')\n",
    "\n",
    "counts3 = Counter(x[0] for x in three_analysis)\n",
    "print(top_five[2])\n",
    "print('No. of positive sentiments    = {}'.format(counts3['positive']))\n",
    "print('No. of neutral sentiments     = {}'.format(counts3['neutral']))\n",
    "print('No. of negative sentiments    = {}'.format(counts3['negative']))\n",
    "print('Total tweets analysed         = {}'.format(len(three_analysis)))\n",
    "print('Percentage of positive tweets = {0:10.3f} %'.format((100*counts3['positive']/len(three_analysis))))\n",
    "print('Percentage of neutral tweets  = {0:10.3f} %'.format((100*counts3['neutral']/len(three_analysis))))\n",
    "print('Percentage of negative tweets = {0:10.3f} %'.format((100*counts3['negative']/len(three_analysis))))\n",
    "print('\\n')\n",
    "\n",
    "counts4 = Counter(x[0] for x in four_analysis)\n",
    "print(top_five[3])\n",
    "print('No. of positive sentiments    = {}'.format(counts4['positive']))\n",
    "print('No. of neutral sentiments     = {}'.format(counts4['neutral']))\n",
    "print('No. of negative sentiments    = {}'.format(counts4['negative']))\n",
    "print('Total tweets analysed         = {}'.format(len(four_analysis)))\n",
    "print('Percentage of positive tweets = {0:10.3f} %'.format((100*counts4['positive']/len(four_analysis))))\n",
    "print('Percentage of neutral tweets  = {0:10.3f} %'.format((100*counts4['neutral']/len(four_analysis))))\n",
    "print('Percentage of negative tweets = {0:10.3f} %'.format((100*counts4['negative']/len(four_analysis))))\n",
    "print('\\n')\n",
    "\n",
    "counts5 = Counter(x[0] for x in five_analysis)\n",
    "print(top_five[4])\n",
    "print('No. of positive sentiments    = {}'.format(counts5['positive']))\n",
    "print('No. of neutral sentiments     = {}'.format(counts5['neutral']))\n",
    "print('No. of negative sentiments    = {}'.format(counts5['negative']))\n",
    "print('Total tweets analysed         = {}'.format(len(five_analysis)))\n",
    "print('Percentage of positive tweets = {0:10.3f} %'.format((100*counts5['positive']/len(five_analysis))))\n",
    "print('Percentage of neutral tweets  = {0:10.3f} %'.format((100*counts5['neutral']/len(five_analysis))))\n",
    "print('Percentage of negative tweets = {0:10.3f} %'.format((100*counts5['negative']/len(five_analysis))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparison between sentiments of tweets and news articles for named-entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A) Entity 1: Hindu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1 = go.Bar(\n",
    "    x=['positive', 'neutral', 'negative'],\n",
    "    y=[(100*counts1['positive']/len(one_analysis)), (100*counts1['neutral']/len(one_analysis)),(100*counts1['negative']/len(one_analysis))],\n",
    "    name='Tweets'\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=['positive', 'neutral', 'negative'],\n",
    "    y=[(100*counts6['positive']/len(body1_analysis)),(100*counts6['neutral']/len(body1_analysis)),(100*counts6['negative']/len(body1_analysis))],\n",
    "    name='News Articles'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    barmode='group',\n",
    "    title='Entity 1: Hindu',\n",
    "    yaxis=dict(\n",
    "        title='Percentage (%)')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity 2: Justin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1 = go.Bar(\n",
    "    x=['positive', 'neutral', 'negative'],\n",
    "    y=[(100*counts2['positive']/len(two_analysis)), (100*counts2['neutral']/len(two_analysis)),(100*counts2['negative']/len(two_analysis))],\n",
    "    name='Tweets'\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=['positive', 'neutral', 'negative'],\n",
    "    y=[(100*counts7['positive']/len(body2_analysis)),(100*counts7['neutral']/len(body2_analysis)),(100*counts7['negative']/len(body2_analysis))],\n",
    "    name='News Articles'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    barmode='group',\n",
    "    title='Entity 2: Justin',\n",
    "    yaxis=dict(\n",
    "        title='Percentage (%)')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity 3: Bieber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1 = go.Bar(\n",
    "    x=['positive', 'neutral', 'negative'],\n",
    "    y=[(100*counts3['positive']/len(three_analysis)), (100*counts3['neutral']/len(three_analysis)),(100*counts3['negative']/len(three_analysis))],\n",
    "    name='Tweets'\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=['positive', 'neutral', 'negative'],\n",
    "    y=[(100*counts8['positive']/len(body3_analysis)),(100*counts8['neutral']/len(body3_analysis)),(100*counts8['negative']/len(body3_analysis))],\n",
    "    name='News Articles'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    barmode='group',\n",
    "    title='Entity 3: Bieber',\n",
    "    yaxis=dict(\n",
    "        title='Percentage (%)')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity 4: #bbmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1 = go.Bar(\n",
    "    x=['positive', 'neutral', 'negative'],\n",
    "    y=[(100*counts4['positive']/len(four_analysis)), (100*counts4['neutral']/len(four_analysis)),(100*counts4['negative']/len(four_analysis))],\n",
    "    name='Tweets'\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=['positive', 'neutral', 'negative'],\n",
    "    y=[(100*counts9['positive']/len(body4_analysis)),(100*counts9['neutral']/len(body4_analysis)),(100*counts9['negative']/len(body4_analysis))],\n",
    "    name='News Articles'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    barmode='group',\n",
    "    title='Entity 4: #bbmas',\n",
    "    yaxis=dict(\n",
    "        title='Percentage (%)')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity 5: Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "trace1 = go.Bar(\n",
    "    x=['positive', 'neutral', 'negative'],\n",
    "    y=[(100*counts5['positive']/len(five_analysis)), (100*counts5['neutral']/len(five_analysis)),(100*counts5['negative']/len(five_analysis))],\n",
    "    name='Tweets'\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=['positive', 'neutral', 'negative'],\n",
    "    y=[(100*counts10['positive']/len(body5_analysis)),(100*counts10['neutral']/len(body5_analysis)),(100*counts10['negative']/len(body5_analysis))],\n",
    "    name='News Articles'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    barmode='group',\n",
    "    title='Entity 5: Trump',\n",
    "    yaxis=dict(\n",
    "        title='Percentage (%)')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
